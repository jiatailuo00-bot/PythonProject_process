#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
æŒ–éœ€å›æµBadCaseå¤„ç†è„šæœ¬
åŠŸèƒ½ï¼š
1. å¤„ç†"æŒ–éœ€å›æµbadcase.xlsx"æ–‡ä»¶
2. æ¸…ç†å†å²å¯¹è¯ä¸­çš„é”€å”®ä¿¡æ¯ï¼ˆå°†[é”€å”®XXX]æ ¼å¼æ”¹ä¸º[é”€å”®]ï¼‰
3. æˆªå–å†å²å¯¹è¯åˆ°æœ€åä¸€æ¡å®¢æˆ·æ¶ˆæ¯
4. æå–RAGå†…å®¹ä¸­çš„ç”¨æˆ·ä¿¡æ¯åº“å’Œé”€å”®ä¿¡æ¯åº“æ•°æ®
5. ç”Ÿæˆç±»ä¼¼"æŒ‰é”€å”®IDåˆ†ç»„çš„æµ‹è¯•é›†å’Œå‘¨æœŸæ ‡ç­¾åˆ†æ.xlsx"çš„æ ¼å¼
"""

import pandas as pd
import numpy as np
import json
import ast
import re
from collections import defaultdict
import sys
import os

class WaxuBadcaseProcessor:
    def __init__(self):
        """åˆå§‹åŒ–æŒ–éœ€å›æµBadCaseå¤„ç†å™¨"""
        self.script_dir = os.path.dirname(os.path.abspath(__file__))
        self.df = None
        self.processed_data = []

    def read_and_process_excel(self, file_path):
        """è¯»å–å¹¶å¤„ç†Excelæ–‡ä»¶"""
        print("æ­£åœ¨è¯»å–æŒ–éœ€å›æµbadcase.xlsxæ–‡ä»¶...")

        try:
            self.df = pd.read_excel(file_path)
            print(f"æ•°æ®æ€»è¡Œæ•°: {len(self.df)}")
            print(f"æ•°æ®åˆ—å: {list(self.df.columns)}")
            print("\nå‰3è¡Œæ•°æ®:")
            print(self.df.head(3))
            return True
        except Exception as e:
            print(f"è¯»å–æ–‡ä»¶å¤±è´¥: {e}")
            return False

    def clean_sales_message_format(self, history_text):
        """
        æ¸…ç†å†å²å¯¹è¯ä¸­çš„é”€å”®æ¶ˆæ¯æ ¼å¼
        å°†[é”€å”®æ©™å•¦å…¬è€ƒåŠ©æ•™ä¹”ä¹”è€å¸ˆ~][æ—¶é—´]æ ¼å¼æ”¹ä¸º[é”€å”®][æ—¶é—´]
        å°†[CSM][æ—¶é—´]æ ¼å¼ä¹Ÿæ”¹ä¸º[é”€å”®][æ—¶é—´]
        """
        if pd.isna(history_text) or history_text == '':
            return ''

        history_str = str(history_text)

        # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼åŒ¹é…[é”€å”®XXX][æ—¶é—´]æ ¼å¼ï¼Œæ›¿æ¢ä¸º[é”€å”®][æ—¶é—´]
        # åŒ¹é…æ¨¡å¼ï¼š[é”€å”®...ä»»æ„å†…å®¹...][æ—¶é—´æˆ³]
        pattern1 = r'\[é”€å”®[^\]]*\](\[\d{4}-\d{2}-\d{2} \d{2}:\d{2}:\d{2}\])'
        cleaned_history = re.sub(pattern1, r'[é”€å”®]\1', history_str)

        # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼åŒ¹é…[CSM][æ—¶é—´]æ ¼å¼ï¼Œæ›¿æ¢ä¸º[é”€å”®][æ—¶é—´]
        # åŒ¹é…æ¨¡å¼ï¼š[CSM][æ—¶é—´æˆ³]
        pattern2 = r'\[CSM\](\[\d{4}-\d{2}-\d{2} \d{2}:\d{2}:\d{2}\])'
        cleaned_history = re.sub(pattern2, r'[é”€å”®]\1', cleaned_history)

        return cleaned_history

    def extract_last_customer_message_history(self, history_text):
        """
        æå–å†å²å¯¹è¯åˆ°æœ€åä¸€æ¡å®¢æˆ·æ¶ˆæ¯ä¸ºæ­¢
        åˆ é™¤æœ€åä¸€æ¡å®¢æˆ·æ¶ˆæ¯ä¹‹åçš„æ‰€æœ‰é”€å”®æ¶ˆæ¯
        """
        if pd.isna(history_text) or history_text == '':
            return '', ''

        history_str = str(history_text)

        # å…ˆæ¸…ç†é”€å”®æ¶ˆæ¯æ ¼å¼
        cleaned_history = self.clean_sales_message_format(history_str)

        # åˆ†å‰²å¯¹è¯æ¶ˆæ¯
        messages = []

        # ä½¿ç”¨æ›´åŠ ç¨³å¥çš„æ­£åˆ™è¡¨è¾¾å¼åŒ¹é…æ¶ˆæ¯å—ï¼Œå…è®¸å¼•ç”¨æ¶ˆæ¯ä¸­å‡ºç°å¸¦[]çš„å†…å®¹
        pattern = r'(\[(?:å®¢æˆ·|é”€å”®)\]\[\d{4}-\d{2}-\d{2} \d{2}:\d{2}:\d{2}\]:[\s\S]*?)(?=\n\[(?:å®¢æˆ·|é”€å”®)\]\[\d{4}-\d{2}-\d{2} \d{2}:\d{2}:\d{2}\]:|\Z)'
        matches = re.findall(pattern, cleaned_history)

        if not matches:
            # å¦‚æœæ­£åˆ™åŒ¹é…å¤±è´¥ï¼Œå°è¯•ç®€å•çš„è¡Œåˆ†å‰²
            lines = cleaned_history.split('\n')
            current_message = ""
            for line in lines:
                if re.match(r'\[(?:å®¢æˆ·|é”€å”®)\]\[\d{4}-\d{2}-\d{2} \d{2}:\d{2}:\d{2}\]:', line):
                    if current_message:
                        messages.append(current_message.strip())
                    current_message = line
                else:
                    if current_message:
                        current_message += "\n" + line
            if current_message:
                messages.append(current_message.strip())
        else:
            messages = matches
        latest_customer_content = ''

        if not messages:
            return cleaned_history, latest_customer_content

        # æ‰¾åˆ°æœ€åä¸€æ¡å®¢æˆ·æ¶ˆæ¯çš„ä½ç½®
        last_customer_index = -1
        for i, message in enumerate(messages):
            if message.startswith('[å®¢æˆ·]'):
                last_customer_index = i

        if last_customer_index == -1:
            # å¦‚æœæ²¡æœ‰æ‰¾åˆ°å®¢æˆ·æ¶ˆæ¯ï¼Œè¿”å›åŸå§‹å†…å®¹
            return cleaned_history, latest_customer_content

        # æˆªå–åˆ°æœ€åä¸€æ¡å®¢æˆ·æ¶ˆæ¯ä¸ºæ­¢
        truncated_messages = messages[:last_customer_index + 1]
        latest_message_raw = messages[last_customer_index]
        latest_customer_content = re.sub(
            r'^\[å®¢æˆ·\]\[\d{4}-\d{2}-\d{2} \d{2}:\d{2}:\d{2}\]:\s*', '', latest_message_raw
        ).strip()

        return '\n'.join(truncated_messages), latest_customer_content

    def extract_rag_content(self, rag_text):
        """
        æå–RAGå†…å®¹ä¸­çš„ç”¨æˆ·ä¿¡æ¯åº“ã€é—®å·ã€è¯•å·ä»¥åŠé”€å”®ä¿¡æ¯åº“æ•°æ®
        """
        result = {
            # ç”¨æˆ·ä¿¡æ¯åº“å­—æ®µ
            'æ‰¹æ¬¡ID': '',
            'æ ‡ç­¾': '',
            'ç”¨æˆ·æ˜µç§°': '',
            'é—®å·å†…å®¹': '',
            'é—®å·æ ‡é¢˜': '',
            'é—®å·ID': '',
            'è¯•å·åç§°': '',
            'è¯•å·ID': '',
            'åˆ†æ•°': '',
            'å¤©': '',
            'æ­£ç¡®ç‡': '',
            'å‘¨æœŸæ‰¹æ¬¡ID': '',
            'å‘¨æœŸæ ‡ç­¾': '',
            # é”€å”®ä¿¡æ¯åº“å­—æ®µ
            'ç›´æ’­è¯¾æ—¶é—´': '',
            'æ¿€æ´»ç›´æ’­è¯¾é“¾æ¥': '',
            'å­¦ä¹ æ¡£æ¡ˆé“¾æ¥': '',
            'æ‰‹æœºå¹³æ¿ä¸Šè¯¾é“¾æ¥': '',
            'ç”µè„‘ä¸Šè¯¾é“¾æ¥': '',
            'ç§’é¢˜æŠ€å·§é“¾æ¥': '',
            'æŠ¥è¯¾é“¾æ¥': '',
            'è¯•å­¦é“¾æ¥': '',
            # RAGæ¥æº
            'ragæ¥æº': 'CSM'
        }

        if pd.isna(rag_text) or rag_text == '':
            return result

        def normalize_content(content):
            """å°†contentç»Ÿä¸€è½¬æ¢ä¸ºåˆ—è¡¨å½¢å¼ï¼Œæ–¹ä¾¿éå†"""
            if isinstance(content, list):
                return content
            if isinstance(content, dict):
                return [content]
            if isinstance(content, str):
                text = content.strip()
                if not text:
                    return []
                try:
                    parsed = json.loads(text)
                    if isinstance(parsed, dict):
                        return [parsed]
                    if isinstance(parsed, list):
                        return parsed
                except Exception:
                    pass
                try:
                    parsed = ast.literal_eval(text)
                    if isinstance(parsed, dict):
                        return [parsed]
                    if isinstance(parsed, list):
                        return parsed
                except Exception:
                    return []
            return []

        def update_sales_info(sales_data, info_dict):
            """æ›´æ–°é”€å”®ä¿¡æ¯å­—æ®µ"""
            fields = [
                'ç›´æ’­è¯¾æ—¶é—´',
                'æ¿€æ´»ç›´æ’­è¯¾é“¾æ¥',
                'å­¦ä¹ æ¡£æ¡ˆé“¾æ¥',
                'æ‰‹æœºå¹³æ¿ä¸Šè¯¾é“¾æ¥',
                'ç”µè„‘ä¸Šè¯¾é“¾æ¥',
                'ç§’é¢˜æŠ€å·§é“¾æ¥',
                'æŠ¥è¯¾é“¾æ¥',
                'è¯•å­¦é“¾æ¥'
            ]
            for field in fields:
                value = sales_data.get(field, '')
                if value:
                    info_dict[field] = value
            return info_dict

        rag_data = {}
        try:
            if isinstance(rag_text, dict):
                rag_data = rag_text
            elif isinstance(rag_text, str):
                text = rag_text.strip()
                if text:
                    try:
                        rag_data = json.loads(text)
                    except Exception:
                        try:
                            rag_data = ast.literal_eval(text)
                        except Exception:
                            rag_data = {}
        except Exception:
            rag_data = {}

        if not isinstance(rag_data, dict):
            return result

        recall_items = []
        if 'data' in rag_data and isinstance(rag_data['data'], dict):
            recall_items = rag_data['data'].get('recall', [])
        elif 'recall' in rag_data:
            recall_items = rag_data.get('recall', [])

        if not isinstance(recall_items, list):
            recall_items = []

        for item in recall_items:
            if not isinstance(item, dict):
                continue

            db_name = item.get('db_name', '')
            content = item.get('content', [])
            source = item.get('source')
            if source:
                result['ragæ¥æº'] = source

            content_list = normalize_content(content)

            if db_name == 'ç”¨æˆ·ä¿¡æ¯åº“':
                for user_data in content_list:
                    if not isinstance(user_data, dict):
                        continue
                    batch_id = user_data.get('æ‰¹æ¬¡ID', '')
                    cycle_batch_id = user_data.get('å‘¨æœŸæ‰¹æ¬¡ID', '')
                    cycle_label = user_data.get('å‘¨æœŸæ ‡ç­¾', '')

                    if batch_id and not result['æ‰¹æ¬¡ID']:
                        result['æ‰¹æ¬¡ID'] = batch_id
                    if cycle_batch_id:
                        result['å‘¨æœŸæ‰¹æ¬¡ID'] = cycle_batch_id
                    elif batch_id and not result['å‘¨æœŸæ‰¹æ¬¡ID']:
                        result['å‘¨æœŸæ‰¹æ¬¡ID'] = batch_id
                    if cycle_label:
                        result['å‘¨æœŸæ ‡ç­¾'] = cycle_label
                    tag_value = user_data.get('æ ‡ç­¾')
                    if isinstance(tag_value, str) and tag_value and not result['æ ‡ç­¾']:
                        result['æ ‡ç­¾'] = tag_value
                    nickname = user_data.get('ç”¨æˆ·æ˜µç§°')
                    if isinstance(nickname, str) and nickname and not result['ç”¨æˆ·æ˜µç§°']:
                        result['ç”¨æˆ·æ˜µç§°'] = nickname

            elif db_name == 'é”€å”®ä¿¡æ¯åº“':
                for sales_data in content_list:
                    if isinstance(sales_data, dict):
                        update_sales_info(sales_data, result)

            elif db_name == 'è°ƒæŸ¥é—®å·åº“':
                for questionnaire_data in content_list:
                    if not isinstance(questionnaire_data, dict):
                        continue
                    content_value = questionnaire_data.get('é—®å·å†…å®¹')
                    if content_value and not result['é—®å·å†…å®¹']:
                        if isinstance(content_value, (dict, list)):
                            result['é—®å·å†…å®¹'] = json.dumps(content_value, ensure_ascii=False)
                        else:
                            result['é—®å·å†…å®¹'] = str(content_value)
                    title = questionnaire_data.get('é—®å·æ ‡é¢˜', '')
                    if title and not result['é—®å·æ ‡é¢˜']:
                        result['é—®å·æ ‡é¢˜'] = title
                    questionnaire_id = questionnaire_data.get('é—®å·ID', '')
                    if questionnaire_id and not result['é—®å·ID']:
                        result['é—®å·ID'] = questionnaire_id

            elif db_name == 'è¯•å·åº“':
                for exam_data in content_list:
                    if not isinstance(exam_data, dict):
                        continue
                    if exam_data.get('è¯•å·åç§°') and not result['è¯•å·åç§°']:
                        result['è¯•å·åç§°'] = exam_data.get('è¯•å·åç§°', '')
                    if exam_data.get('è¯•å·ID') and not result['è¯•å·ID']:
                        result['è¯•å·ID'] = exam_data.get('è¯•å·ID', '')
                    if exam_data.get('åˆ†æ•°') and not result['åˆ†æ•°']:
                        result['åˆ†æ•°'] = str(exam_data.get('åˆ†æ•°', ''))
                    if exam_data.get('å¤©') and not result['å¤©']:
                        result['å¤©'] = str(exam_data.get('å¤©', ''))
                    if exam_data.get('æ­£ç¡®ç‡') and not result['æ­£ç¡®ç‡']:
                        result['æ­£ç¡®ç‡'] = str(exam_data.get('æ­£ç¡®ç‡', ''))

        return result

    def is_question_keyword_based(self, message):
        """åŸºäºæ›´ç²¾å‡†çš„è§„åˆ™åˆ¤æ–­æ¶ˆæ¯æ˜¯å¦ä¸ºé—®å¥"""
        if pd.isna(message) or message == '':
            return 'å¦'

        message_str = str(message).strip()

        if not message_str:
            return 'å¦'

        # 1. ç›´æ¥åŒ…å«é—®å·
        if any(ch in message_str for ch in ('?', 'ï¼Ÿ')):
            return 'æ˜¯'

        # æ ‡å‡†åŒ–å°¾éƒ¨æ ‡ç‚¹
        stripped = re.sub(r'[ã€‚ï¼\.â€¦!ï¼ï¼›;,\s]+$', '', message_str)

        # 2. å¸¸è§é—®å¥ç»“å°¾ç²’åº¦ï¼ˆè¦æ±‚å‡ºç°åœ¨æœ«å°¾ä»¥å‡å°‘è¯¯æŠ¥ï¼‰
        ending_patterns = [
            r'(å—|å˜›|ä¹ˆ|å‘¢|å§)$',
            r'(å¯¹å—|å¯¹å§|å¥½ä¸å¥½|è¦ä¸è¦|è¡Œä¸è¡Œ|æ˜¯ä¸æ˜¯|å¯ä¸å¯ä»¥|èƒ½ä¸èƒ½|è¡Œå—|è¡Œä¹ˆ|è¡Œå˜›|å¥½å—|å¥½ä¹ˆ|å¥½å˜›)$'
        ]
        for pattern in ending_patterns:
            if re.search(pattern, stripped):
                return 'æ˜¯'

        # 3.a ä»¥èƒ½åŠ›/è®¸å¯ç±»è¯æ±‡å¼€å¤´çš„ç–‘é—®
        if stripped.startswith(('èƒ½å¦', 'æ˜¯å¦', 'å¯å¦', 'èƒ½ä¸èƒ½')):
            return 'æ˜¯'

        # 3.b ä»¥ç–‘é—®ä»£è¯å¼€å¤´çš„ç»“æ„
        interrogative_starts = ('ä»€ä¹ˆ', 'æ€ä¹ˆ', 'æ€æ ·', 'ä¸ºä½•', 'ä¸ºä»€ä¹ˆ', 'å“ªä¸ª', 'å“ªç§', 'å“ªäº›',
                                'å“ªé‡Œ', 'å“ªå„¿', 'å“ªå®¶', 'å“ªä½', 'è°', 'ä½•æ—¶', 'å‡ æ—¶', 'å¤šå°‘', 'å¤šä¹…',
                                'å¤šé•¿', 'å¤šè¿œ', 'å¤šå¤§', 'å¤šé«˜', 'å¤šé‡', 'å‡ å²', 'å‡ å¤©', 'å‡ æœˆ', 'å‡ å·')
        for start in interrogative_starts:
            if stripped.startswith(start):
                return 'æ˜¯'

        # 3. ç»„åˆé—®å¥ç»“æ„
        combo_patterns = [
            r'(?:å¯ä¸å¯ä»¥|èƒ½ä¸èƒ½|è¦ä¸è¦|å¥½ä¸å¥½|è¡Œä¸è¡Œ)',
            r'(?:èƒ½å¦|æ˜¯å¦|å¯å¦)[^ã€‚ï¼ï¼Ÿ]*?(?:å—|å‘¢|å§|\?|ï¼Ÿ)'
        ]
        for pattern in combo_patterns:
            if re.search(pattern, message_str):
                return 'æ˜¯'

        # 4. å«â€œè¯·é—®â€ä¸”ä¼´éšèƒ½åŠ›/è®¸å¯ç±»åŠ¨è¯çš„å¥å¼
        if 'è¯·é—®' in message_str and re.search(r'(?:å¯ä»¥|èƒ½|èƒ½å¦|æ˜¯å¦|å¯å¦)', message_str):
            return 'æ˜¯'

        return 'å¦'

    def extract_thought_unit_info(self, thought_unit_text):
        """æå–thought_unitä¸­çš„å‘¨æœŸæ ‡ç­¾ä¿¡æ¯"""
        if pd.isna(thought_unit_text) or thought_unit_text == '':
            return {'å‘¨æœŸæ ‡ç­¾': ''}

        try:
            if isinstance(thought_unit_text, str):
                thought_data = json.loads(thought_unit_text)
            else:
                thought_data = thought_unit_text

            # ä»rag_chat_request_bodyä¸­æå–å‘¨æœŸæ ‡ç­¾
            if 'rag_chat_request_body' in thought_data:
                rag_request = thought_data['rag_chat_request_body']
                if 'contexts' in rag_request:
                    # è¿™é‡Œå¯ä»¥è¿›ä¸€æ­¥å¤„ç†contextsæ¥æå–å‘¨æœŸä¿¡æ¯
                    pass

            # ä»rag_chat_resultä¸­æå–ç”¨æˆ·ä¿¡æ¯
            if 'rag_chat_result' in thought_data:
                rag_result = thought_data['rag_chat_result']
                if isinstance(rag_result, str):
                    try:
                        rag_result_data = json.loads(rag_result)
                        for item in rag_result_data:
                            if item.get('db_name') == 'ç”¨æˆ·ä¿¡æ¯åº“':
                                content = item.get('content', [])
                                if content and len(content) > 0:
                                    user_data = content[0]
                                    cycle_label = user_data.get('å‘¨æœŸæ ‡ç­¾', '')
                                    if cycle_label:
                                        return {'å‘¨æœŸæ ‡ç­¾': cycle_label}
                    except:
                        pass

        except Exception as e:
            print(f"è§£æthought_unitæ•°æ®æ—¶å‡ºé”™: {str(e)}")

        return {'å‘¨æœŸæ ‡ç­¾': ''}

    def process_data_by_sales_id(self):
        """æŒ‰é”€å”®IDåˆ†ç»„å¤„ç†æ•°æ®ï¼Œç”Ÿæˆæµ‹è¯•é›†æ ¼å¼"""
        print("\n=== å¼€å§‹å¤„ç†æŒ–éœ€å›æµbadcaseæ•°æ® ===")

        if self.df is None or self.df.empty:
            print("âŒ æ²¡æœ‰å¯ç”¨çš„æ•°æ®")
            return False

        # è·å–æ‰€æœ‰å”¯ä¸€çš„é”€å”®ID
        unique_sales_ids = self.df['é”€å”®ID'].unique()
        print(f"å…±å‘ç° {len(unique_sales_ids)} ä¸ªé”€å”®ID")

        all_processed_data = []
        sales_summary = []

        for sales_id in unique_sales_ids:
            print(f"\nå¤„ç†é”€å”®ID: {sales_id[:30]}...")

            # ç­›é€‰å½“å‰é”€å”®çš„æ•°æ®
            sales_data = self.df[self.df['é”€å”®ID'] == sales_id].copy()
            print(f"  åŸå§‹è®°å½•æ•°: {len(sales_data)}")

            # è·å–é”€å”®åç§°
            sales_name = sales_data['é”€å”®åç§°'].iloc[0] if not sales_data.empty and 'é”€å”®åç§°' in sales_data.columns else "æœªçŸ¥"

            # æŒ‰å®¢æˆ·IDåˆ†ç»„å¤„ç†
            customers_in_sales = sales_data['å®¢æˆ·ID'].unique()
            print(f"  å®¢æˆ·æ•°é‡: {len(customers_in_sales)}")

            processed_count = 0

            for customer_id in customers_in_sales:
                # è·å–è¯¥å®¢æˆ·çš„æ‰€æœ‰è®°å½•
                customer_data = sales_data[sales_data['å®¢æˆ·ID'] == customer_id].copy()

                # ä¸ºæ¯æ¡è®°å½•åˆ›å»ºä¸€ä¸ªæµ‹è¯•ç”¨ä¾‹
                for _, record in customer_data.iterrows():
                    try:
                        # å¤„ç†å†å²å¯¹è¯å¹¶æå–æœ€æ–°å®¢æˆ·æ¶ˆæ¯
                        cleaned_history, latest_customer_msg = self.extract_last_customer_message_history(record['å†å²å¯¹è¯'])
                        original_customer_msg = str(record.get('å®¢æˆ·æ¶ˆæ¯', '') or '').strip()
                        latest_customer_msg = latest_customer_msg if latest_customer_msg else original_customer_msg

                        # æå–RAGå†…å®¹
                        rag_data = self.extract_rag_content(record['rag'])

                        # æå–thought_unitä¿¡æ¯
                        thought_info = self.extract_thought_unit_info(record['thought_unit'])

                        # åˆ¤æ–­æ˜¯å¦æ˜¯é—®å¥
                        is_question = self.is_question_keyword_based(latest_customer_msg)

                        # å‘¨æœŸæ ‡ç­¾ä¼˜å…ˆä½¿ç”¨RAGç»“æœï¼Œå…¶æ¬¡thought_unit
                        cycle_label = rag_data.get('å‘¨æœŸæ ‡ç­¾') or thought_info.get('å‘¨æœŸæ ‡ç­¾', '')

                        # æ„å»ºå¤„ç†åçš„è®°å½•
                        processed_record = {
                            'é”€å”®ID': record['é”€å”®ID'],
                            'å®¢æˆ·ID': record['å®¢æˆ·ID'],
                            'å‘é€æ–¹': record.get('å‘é€æ–¹', ''),
                            'å†å²å¯¹è¯': cleaned_history,
                            'åŸå§‹å®¢æˆ·æ¶ˆæ¯': original_customer_msg,
                            'æœ€æ–°å®¢æˆ·æ¶ˆæ¯': latest_customer_msg,
                            'rag': record.get('rag', ''),
                            'thought_unit': record.get('thought_unit', ''),
                            'å‘¨æœŸæ ‡ç­¾': cycle_label,
                            'æ˜¯å¦æ˜¯é—®å¥': is_question,
                            'å®¢æˆ·æ¶ˆæ¯æ—¶é—´': record.get('å®¢æˆ·æ¶ˆæ¯æ—¶é—´', ''),
                            'å‘é€æ—¶é—´': record.get('å‘é€æ—¶é—´', ''),
                            'ragæ¥æº': rag_data['ragæ¥æº'],
                            # åŸè¡¨ä¸­çš„é‡è¦å­—æ®µ
                            'å½“å‰é”€å”®é˜¶æ®µ': record.get('å½“å‰é”€å”®é˜¶æ®µ', ''),
                            'å½“å‰é”€å”®åŠ¨ä½œ': record.get('å½“å‰é”€å”®åŠ¨ä½œ', ''),
                            'å›å¤ç­–ç•¥': record.get('å›å¤ç­–ç•¥', ''),
                            'AIç”Ÿæˆæ¶ˆæ¯': record.get('AIç”Ÿæˆæ¶ˆæ¯', ''),
                            'å‘é€æ¶ˆæ¯å†…å®¹': record.get('å‘é€æ¶ˆæ¯å†…å®¹', ''),
                            'è´¨æ£€ç»“æœ': record.get('è´¨æ£€ç»“æœ', ''),
                            'è´¨æ£€åŸå› ': record.get('è´¨æ£€åŸå› ', ''),
                            # ç”¨æˆ·ä¿¡æ¯åº“å­—æ®µ
                            'æ‰¹æ¬¡ID': rag_data['æ‰¹æ¬¡ID'],
                            'é—®å·å†…å®¹': rag_data['é—®å·å†…å®¹'],
                            'é—®å·æ ‡é¢˜': rag_data['é—®å·æ ‡é¢˜'],
                            'é—®å·ID': rag_data['é—®å·ID'],
                            'è¯•å·åç§°': rag_data['è¯•å·åç§°'],
                            'è¯•å·ID': rag_data['è¯•å·ID'],
                            'åˆ†æ•°': rag_data['åˆ†æ•°'],
                            'å¤©': rag_data['å¤©'],
                            'æ­£ç¡®ç‡': rag_data['æ­£ç¡®ç‡'],
                            'å‘¨æœŸæ‰¹æ¬¡ID': rag_data['å‘¨æœŸæ‰¹æ¬¡ID'],
                            'æ ‡ç­¾': rag_data['æ ‡ç­¾'],
                            'ç”¨æˆ·æ˜µç§°': rag_data['ç”¨æˆ·æ˜µç§°'],
                            # é”€å”®ä¿¡æ¯åº“å­—æ®µ
                            'ç›´æ’­è¯¾æ—¶é—´': rag_data['ç›´æ’­è¯¾æ—¶é—´'],
                            'æ¿€æ´»ç›´æ’­è¯¾é“¾æ¥': rag_data['æ¿€æ´»ç›´æ’­è¯¾é“¾æ¥'],
                            'å­¦ä¹ æ¡£æ¡ˆé“¾æ¥': rag_data['å­¦ä¹ æ¡£æ¡ˆé“¾æ¥'],
                            'æ‰‹æœºå¹³æ¿ä¸Šè¯¾é“¾æ¥': rag_data['æ‰‹æœºå¹³æ¿ä¸Šè¯¾é“¾æ¥'],
                            'ç”µè„‘ä¸Šè¯¾é“¾æ¥': rag_data['ç”µè„‘ä¸Šè¯¾é“¾æ¥'],
                            'ç§’é¢˜æŠ€å·§é“¾æ¥': rag_data['ç§’é¢˜æŠ€å·§é“¾æ¥'],
                            'æŠ¥è¯¾é“¾æ¥': rag_data['æŠ¥è¯¾é“¾æ¥'],
                            'è¯•å­¦é“¾æ¥': rag_data['è¯•å­¦é“¾æ¥'],
                            # é¢„æœŸå›å¤å­—æ®µï¼ˆä¿ç•™ä¸ºç©ºï¼Œåç»­å¯ä»¥å¡«å……ï¼‰
                            'æœ€åé”€å”®æ¶ˆæ¯': [],
                            'é¢„æœŸé”€å”®å›å¤': '',
                            'å¤‡é€‰é”€å”®å›å¤': []
                        }

                        all_processed_data.append(processed_record)
                        processed_count += 1

                    except Exception as e:
                        print(f"  âŒ å¤„ç†è®°å½•å¤±è´¥: {e}")
                        continue

            # ç»Ÿè®¡ä¿¡æ¯
            sales_summary.append({
                'é”€å”®ID': sales_id,
                'é”€å”®åç§°': sales_name,
                'å®¢æˆ·æ•°é‡': len(customers_in_sales),
                'è®°å½•æ•°': len(sales_data),
                'å¤„ç†æˆåŠŸæ•°': processed_count
            })

            print(f"  å¤„ç†å®Œæˆ: {processed_count} æ¡è®°å½•")

        self.processed_data = all_processed_data

        print(f"\n=== å¤„ç†å®Œæˆ ===")
        print(f"æ€»å¤„ç†è®°å½•æ•°: {len(all_processed_data)}")

        return True

    def save_results(self, output_file="1104æŒ–éœ€ä¿®æ”¹æ•°æ®-yyds.xlsx"):
        """ä¿å­˜å¤„ç†ç»“æœ"""
        if not self.processed_data:
            print("âŒ æ²¡æœ‰å¤„ç†åçš„æ•°æ®å¯ä¿å­˜")
            return False

        try:
            # è½¬æ¢ä¸ºDataFrame
            test_df = pd.DataFrame(self.processed_data)

            # æå–thought_unitå­—æ®µä¿¡æ¯
            test_df = extract_thought_unit_fields(test_df)
            self.processed_data = test_df.to_dict('records')

            # æ ‡å‡†æ ¼å¼åˆ—ï¼ˆåŒ…å«åŸè¡¨é‡è¦å­—æ®µï¼‰
            standard_columns = [
                'é”€å”®ID', 'å®¢æˆ·ID', 'å‘é€æ–¹', 'å†å²å¯¹è¯', 'åŸå§‹å®¢æˆ·æ¶ˆæ¯', 'æœ€æ–°å®¢æˆ·æ¶ˆæ¯', 'rag', 'thought_unit',
                'å¼ºéµå¾ªæ ‡ç­¾', 'FAQåˆ¤æ–­', 'çŸ¥è¯†é—®ç­”åˆ¤æ–­', 'é”€å”®ä¸€çº§èŠ‚ç‚¹', 'é”€å”®äºŒçº§èŠ‚ç‚¹', 'reference_script',
                'å‘¨æœŸæ ‡ç­¾', 'æ˜¯å¦æ˜¯é—®å¥', 'å®¢æˆ·æ¶ˆæ¯æ—¶é—´', 'å‘é€æ—¶é—´', 'ragæ¥æº',
                # åŸè¡¨ä¸­çš„é‡è¦å­—æ®µ
                'å½“å‰é”€å”®é˜¶æ®µ', 'å½“å‰é”€å”®åŠ¨ä½œ', 'å›å¤ç­–ç•¥', 'AIç”Ÿæˆæ¶ˆæ¯', 'å‘é€æ¶ˆæ¯å†…å®¹', 'è´¨æ£€ç»“æœ', 'è´¨æ£€åŸå› ',
                # RAGæå–çš„å­—æ®µ
                'æ‰¹æ¬¡ID', 'é—®å·å†…å®¹', 'é—®å·æ ‡é¢˜', 'é—®å·ID', 'è¯•å·åç§°', 'è¯•å·ID', 'åˆ†æ•°', 'å¤©', 'æ­£ç¡®ç‡', 'å‘¨æœŸæ‰¹æ¬¡ID',
                'æ ‡ç­¾', 'ç”¨æˆ·æ˜µç§°',
                'ç›´æ’­è¯¾æ—¶é—´', 'æ¿€æ´»ç›´æ’­è¯¾é“¾æ¥', 'å­¦ä¹ æ¡£æ¡ˆé“¾æ¥', 'æ‰‹æœºå¹³æ¿ä¸Šè¯¾é“¾æ¥', 'ç”µè„‘ä¸Šè¯¾é“¾æ¥',
                'ç§’é¢˜æŠ€å·§é“¾æ¥', 'æŠ¥è¯¾é“¾æ¥', 'è¯•å­¦é“¾æ¥', 'æœ€åé”€å”®æ¶ˆæ¯', 'é¢„æœŸé”€å”®å›å¤', 'å¤‡é€‰é”€å”®å›å¤'
            ]

            # ç¡®ä¿æ‰€æœ‰åˆ—éƒ½å­˜åœ¨
            for col in standard_columns:
                if col not in test_df.columns:
                    test_df[col] = ''

            standard_test_df = test_df[standard_columns].copy()

            # ä¿å­˜åˆ°Excelæ–‡ä»¶
            with pd.ExcelWriter(output_file, engine='openpyxl') as writer:
                # æ ‡å‡†æ ¼å¼æµ‹è¯•é›†
                standard_test_df.to_excel(writer, sheet_name='æµ‹è¯•é›†_æ ‡å‡†æ ¼å¼', index=False)

                # å®Œæ•´ä¿¡æ¯æµ‹è¯•é›†
                test_df.to_excel(writer, sheet_name='æµ‹è¯•é›†_å®Œæ•´ä¿¡æ¯', index=False)

            print(f"âœ… å¤„ç†ç»“æœå·²ä¿å­˜åˆ°: {output_file}")
            print(f"åŒ…å«å·¥ä½œè¡¨:")
            print(f"  - æµ‹è¯•é›†_æ ‡å‡†æ ¼å¼: {len(standard_test_df)} æ¡è®°å½•")
            print(f"  - æµ‹è¯•é›†_å®Œæ•´ä¿¡æ¯: {len(test_df)} æ¡è®°å½•")

            return True

        except Exception as e:
            print(f"âŒ ä¿å­˜ç»“æœå¤±è´¥: {e}")
            return False

def extract_thought_unit_fields(df: pd.DataFrame) -> pd.DataFrame:
    """
    ä»thought_unitå­—æ®µä¸­æå–å¼ºéµå¾ªã€FAQåˆ¤æ–­ã€çŸ¥è¯†é—®ç­”åˆ¤æ–­ã€é”€å”®èŠ‚ç‚¹å’Œreference_scriptä¿¡æ¯
    """
    target_columns = {
        'å¼ºéµå¾ªæ ‡ç­¾': 'False',
        'FAQåˆ¤æ–­': 'False',
        'çŸ¥è¯†é—®ç­”åˆ¤æ–­': 'False',
        'é”€å”®ä¸€çº§èŠ‚ç‚¹': '',
        'é”€å”®äºŒçº§èŠ‚ç‚¹': '',
        'reference_script': ''
    }

    for col, default in target_columns.items():
        if col not in df.columns:
            df[col] = default
        else:
            df[col] = df[col].fillna(default)

    if 'thought_unit' not in df.columns:
        df['thought_unit'] = ''
        return df

    for idx, row in df.iterrows():
        thought_unit = row.get('thought_unit', '')

        # é»˜è®¤å€¼
        df.at[idx, 'å¼ºéµå¾ªæ ‡ç­¾'] = 'False'
        df.at[idx, 'FAQåˆ¤æ–­'] = 'False'
        df.at[idx, 'çŸ¥è¯†é—®ç­”åˆ¤æ–­'] = 'False'
        df.at[idx, 'é”€å”®ä¸€çº§èŠ‚ç‚¹'] = ''
        df.at[idx, 'é”€å”®äºŒçº§èŠ‚ç‚¹'] = ''
        df.at[idx, 'reference_script'] = ''

        if pd.isna(thought_unit) or str(thought_unit).strip() == '':
            continue

        try:
            tu_obj = json.loads(str(thought_unit))
        except json.JSONDecodeError:
            continue
        except Exception:
            continue

        # 1. å¼ºéµå¾ªæ ‡ç­¾
        endpoint_step = tu_obj.get('endpoint_step', '')
        if endpoint_step == 'å¼ºéµå¾ª':
            df.at[idx, 'å¼ºéµå¾ªæ ‡ç­¾'] = 'True'

        # 2. FAQåˆ¤æ–­
        rag_fast_result = tu_obj.get('rag_fast_chat_result', '')
        is_faq = False
        if isinstance(rag_fast_result, str):
            clean_result = rag_fast_result.strip()
            is_faq = bool(clean_result and clean_result != '[]')
        elif isinstance(rag_fast_result, list):
            is_faq = len(rag_fast_result) > 0
        elif rag_fast_result:
            is_faq = True
        df.at[idx, 'FAQåˆ¤æ–­'] = 'True' if is_faq else 'False'

        # 3. çŸ¥è¯†é—®ç­”åˆ¤æ–­
        knowledge_result = tu_obj.get('knowledge_scenario_result', False)
        df.at[idx, 'çŸ¥è¯†é—®ç­”åˆ¤æ–­'] = 'True' if knowledge_result is True else 'False'

        # 4. é”€å”®èŠ‚ç‚¹
        rag_history_body = tu_obj.get('rag_history_chat_request_body', {})
        if isinstance(rag_history_body, dict):
            node_1st = rag_history_body.get('node_1st', '')
            node_2nd = rag_history_body.get('node_2nd', '')
            if node_1st:
                df.at[idx, 'é”€å”®ä¸€çº§èŠ‚ç‚¹'] = node_1st
            if node_2nd:
                df.at[idx, 'é”€å”®äºŒçº§èŠ‚ç‚¹'] = node_2nd

        # 5. reference_script
        reference_script = tu_obj.get('reference_script', '')
        if isinstance(reference_script, list):
            df.at[idx, 'reference_script'] = json.dumps(reference_script, ensure_ascii=False)
        elif reference_script:
            df.at[idx, 'reference_script'] = str(reference_script)

    return df


def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ¤– æŒ–éœ€å›æµBadCaseå¤„ç†è„šæœ¬")
    print("ä½œè€…: Claude Code")
    print("ç‰ˆæœ¬: v1.0")
    print()

    # åˆ›å»ºå¤„ç†å™¨å®ä¾‹
    processor = WaxuBadcaseProcessor()

    # è¯»å–å¹¶å¤„ç†Excelæ–‡ä»¶
    input_file = "1104æŒ–éœ€ä¿®æ”¹æ•°æ®2.xlsx"
    if not processor.read_and_process_excel(input_file):
        print("ğŸ’¥ è¯»å–æ–‡ä»¶å¤±è´¥")
        return 1

    # å¤„ç†æ•°æ®
    if not processor.process_data_by_sales_id():
        print("ğŸ’¥ æ•°æ®å¤„ç†å¤±è´¥")
        return 1

    # ä¿å­˜ç»“æœ
    if not processor.save_results():
        print("ğŸ’¥ ä¿å­˜ç»“æœå¤±è´¥")
        return 1

    print("\nğŸ‰ æŒ–éœ€å›æµBadCaseå¤„ç†å®Œæˆï¼")
    return 0

if __name__ == "__main__":
    exit_code = main()
    sys.exit(exit_code)
